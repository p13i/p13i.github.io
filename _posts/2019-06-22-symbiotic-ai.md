---
title: Symbiotic Artificial Intelligence
date: 2019-06-22 00:00:00 Z
categories:
- writing
tags:
- artificial-intelligence
- human-computer-interaction
author: Pramod Kotipalli
description: An evolving catalog of what I’ve learned in the fields of artificial
  intelligence and human-computer interaction.
layout: posts/post
---

# Introduction

We are witness to the convergence of multiple scientific trends that will enable us humans to take control of our bodies like never before: CRISPR allows us humans to modify our own DNA, the internet augments the human memory to the entire sum of human *memory*, AI will allow humans to process inordinate amounts of information thus increasing the scope of our *intuition*, and AR will increase the information bandwidth of our senses.

It’s a matter of *when* we humans will gain full control over evolution: we will soon be able to control our genetics and augment the brain that allowed us to become the dominant creatures on Earth.

*Symbiotic Artificial Intelligence* is a term that encompasses a broad set of fields in computing. It expresses the principle that humans and machines can learn from each other in a way that improves the way humans live and work in the real world. Symbiotic AI is a fundamentally optimistic view of the future of human-computer interaction. Symbiotic AI also takes on synonymous terms like “human-machine symbiosis” and (less commonly) “human-machine co-evolution”. For our purposes, the word “machine” can be used interchangeably with “computer.”

Symbiotic AI can take many forms:
* a 12 year old spending the entire day with her smartphone being able to research any fact from all of human knowledge after just a few taps, or
* a student using a Remembrance Agent [[Rhodes 1997]](https://paperpile.com/c/mpEskP/0nl3) to automatically pull up meeting notes with every person he’s ever met, or
* a “Borg” like creature (see *Star Trek: Voyager*) merging man and literal metal into one being.

|||![None](https://lh4.googleusercontent.com/7HNlk43p7KUCY1hgNfoWGnFD6UYMsbq-i-QOPFAgkZaLEdKj6CNsmGlHu8_zQ91hkqWhjLorteUq7xLS5DTsh9AktlPzNmii8bPBc0WR7KUd7bKMYb2QNJOzTpGjGRTNXnEL7r07_EzVAS-SNg)|
|---|---|---|
|||*Seven of Nine *from *Star Trek: Voyager *[[Fleenor 2019]](https://paperpile.com/c/mpEskP/cNpY)|


In this document, I will investigate non-invasive forms of human augmentation as opposed to those integrations that require implants, insertions into, or piercing of the body. Such integrated devices are able to take more accurate measure of our physiology and can also communicate more efficiently with organs like our sub-epidermal skin and brain. However, these implanted devices are unlikely to be adopted in the near future due to fears over personal injury and the idea of ‘having a computer inside your body.’

The focus of this document will be on non-invasive wearable technologies like head-worn displays and wrist-worn displays (i.e. smartwatches). This category of devices offer many benefits (explored in depth later) including the option of “turning off” the system and removing wearable augmentations with ease. Wearable computers are also much more socially acceptable than implanted devices for the time being.

# Human-Machine Symbiosis

## Closing the loop between *intention* and *action*

The first, and perhaps most important, principle of Symbiotic AI is of reducing the time (and effort) between intention and action. Once the time between intent and action reduces below two seconds, we are able to start forming habits. 

Reducing this delta is the premise behind a multi-billion dollar online shopping industry: Amazon’s patented 1-Click [[Hartman et al. 1999]](https://paperpile.com/c/mpEskP/jiKd) system eliminates the time needed to check out through a shopping cart. Amazon’s Dash Buttons further reduces this delta by removing a screen from the purchasing interaction: a single tap of a tangible button is all that’s needed to order common consumables. Once a habit is formed, it’s ingrained, it’s useful, and it’s profitable (for those of that persuasion).

*The distance between action and intent*: It’s a key concept for the melding of men and machines, humans and AI. Reduce the overhead of a communication bridge or the time to act on a thought. Then habits are formed and we get closer to achieving our goals and our machines get closer to us.

## Bridging the biological and the digital

[[Maes 1997]](https://paperpile.com/c/mpEskP/se69) observes that we’ve experienced a revolution in computing in the past 30 years: our bodies have been augmented in a significant and permanent way; the two “halves” of our brains are no longer the “left” or “right” but instead the biological we are given and the digital we use to voluntarily augment our memory and communication. Maes provides a compelling way to think about 

The interface between our biological and digital worlds is currently mediated by smartphones and laptops. These interfaces are marked by three fundamental problems:
* I/O bandwidth is limited,
* they requires our complete attention, disengaging us from the physical world,
* they serve to distract us quite often as they aren’t necessarily designed for the goals of people in mind.

Different apps on phones are designed to distract you as much as possible, making you as inefficient and ineffective in accomplishing goals leading to increased “multitasking” which contributes to shorter attention spans and worse memory recall [[Stanford University 2018]](https://paperpile.com/c/mpEskP/HdB0).

[[Maes 1997]](https://paperpile.com/c/mpEskP/se69) argued that we will become one with the computer, but we must redesign the experience of how we interact with their digital devices. In this direction, Maes argues for a new approach built upon three pillars:
* A system aware of context and a user’s internal state. It pays attention to what the user is paying attention to, to brain activity, heart rate, breathing rate, etc.
* An always-on augmented interface integrated in a seamless and non-disruptive way.
* A system that has its roots in proactive and personalized interaction that offers relevant information and intervention, given what the user is currently trying to do, the user’s state, and the user’s real/human goals.

In this direction, a symbiotic relationship between users and machines will help with self-actualization itself. It will aid us in growing and developing into the people we want to become: We all want to change and grow in different ways; we will rely on symbiotic forms of personal devices more and more to help us change with time.

Maes outlines four broad categories in which symbiotic systems can support humans:
* Supporting Decision Making
* Supporting Learning
* Supporting Memory
* Supporting Mood and Well-being

We will discuss each of these categories in the following chapters.
## 
# Augmented Reality

Augmented reality refers to any augmentation of our natural senses[^footnote-1]. Augmented reality encompases traditional experiences like those provided in smartphones today[^footnote-2]. It also includes experiences delivered in fully-immersive Virtual Reality experiences. We can represent AR on a spectrum from the real world to that of the virtual:

![None](/static/images/2019-06-22-symbiotic-ai/image0.png)
Figure: [[Milgram et al. 1995]](https://paperpile.com/c/mpEskP/ZNyK)

On this particular spectrum exist two primary stages of manipulation:
* Augmented reality
* Virtual reality

A second, more useful spectrum exists on the scale of VR to AR. “True AR” encompasses a system “[fused coherently] with the user’s real environment.” In traditional formulations of AR, AR forms a proper superset of VR where in VR “we just need to block the user’s experience of the real world.” [[Sandor et al. 2015]](https://paperpile.com/c/mpEskP/8tj6) Thus, as VR substitutes the entire visual experience, it demands a higher-level of realism than AR. [[Sandor et al. 2015]](https://paperpile.com/c/mpEskP/8tj6) segment their approaches to AR into four categories ranging from “manipulating atoms” to “manipulating perception”:

* Controlled Matter
* Surround AR
* Personalized AR
* Implanted AR

## The Reality-Virtuality Spectrum

There is quite a bit of marketing language from head-worn display manufacturers that occludes a simple understanding of this subject.

### Real environment

Simple enough to grasp, this is the real world in which we all reside and perceive. 

### Augmented reality (AR)

This form of augmentation encompasses a broader scope of marketing terms including divided into two broad categories:
* those involving registered graphics and
* those involving static graphics.
It’s important to note that both static and registered graphics can still make use of contextual information[^footnote-3] in similar ways; only the mechanism of conveying such information is different between these forms of AR.

#### Registered graphics

Registered graphics encompasses technologies developed by Microsoft (“Mixed Reality”) or augmented reality solutions developed in the research literature (e.g. Starner, Feiner, et. al) known as registered AR or spatial AR.

This form of AR involves placing virtual computer artifacts into the real world by either:
* displaying such graphics through a traditional display (i.e. an iPhone running ARKit), or
* displaying such graphics through a holographic display (i.e. a HoloLens).

![None](/static/images/2019-06-22-symbiotic-ai/image1.png)
A holographic display placing registered graphics into the real world. Figure: [[Buntz]](https://paperpile.com/c/mpEskP/L36u)

#### Static graphics

Depending on the use case, static graphics may be more applicable. This form involves displaying static information generated by a computer that *does not* include an image of the real environment.

### Virtual Reality
### 
Virtual reality (VR) involves complete immersion in a virtual environment with little or none of the real environment available to the user.
![None](/static/images/2019-06-22-symbiotic-ai/image2.png)

Figure: [[[CSL STYLE ERROR: reference with no printed form.]]](https://paperpile.com/c/mpEskP/KjLj)

## Augmented Reality Spectrum

This spectrum exists on a different axis from the Reality-Virtuality Spectrum and discusses the theoretical mechanisms with which reality can be manipulated.

### Controlled Matter

![None](/static/images/2019-06-22-symbiotic-ai/image3.png)
Figure: [[Zambetta 2017]](https://paperpile.com/c/mpEskP/KEbv)

Think The HoloDeck from *Star Trek*: matter is created and destroyed, or at the minimum photons are controlled by ‘force fields’ giving the impression of physical objects and interactions.

Another, more tangible[^footnote-4], example is the [inFORM project](https://tangible.media.mit.edu/project/inform/) from MIT Media Lab:
![None](/static/images/2019-06-22-symbiotic-ai/image4.png)
Figure: [[2013]](https://paperpile.com/c/mpEskP/HJKN)

[[Sandor et al. 2015]](https://paperpile.com/c/mpEskP/8tj6) notes Sutherland’s suggestion that physically creating and destroying atoms forms an ideal for True AR because it would “create physical objects consistent over all interaction modalities and all users.”

### Surround AR

The next level closer to the user is by “manipulating [the] photons” that reach them. Surround AR lacks the physical interactivity enabled by Controlled Matter but can create an augmented reality indistinguishable from physical reality.

Think of an empty room panelled with high-fidelity displays. As the user walks around, her entire perception of the room changes. You can simulate what it’s like to stand in Wrigley Field: as your head moves around the room, the environment tracks you, and updates the environment accordingly to provide the illusion of movement.

However, if you were at Wrigley Field, you couldn’t sit down at the bleeachers and enjoy a hot dog. Matter itself isn’t manipulated, only light.

### Personalized AR

HWDs like Google Glass or Magic Leap provide us with this level of augmentation. Our visual field is augmented with new objects placed indistinguishably from the physical world. Each user augments their own visual perception. This doesn’t preclude shared experiences but requires some level high-speed networking.

### Implant AR

Completely invisible to the outside world, this level of AR involves directly manipulating where visual perception is interpreted: in our brains. An implant is placed in or near the visual cortex and directly manipulates our perception of the physical world.

Think controlled LSD trip.

## 
## The Case for Non-Visual AR

Many primary tasks in our lives (such as driving, studying, or playing with friends) require a significant amount of visual attention and engagement in the natural, physical, non-visually-augmented world. In these situations, it is safer to manipulate a different sense than the visual one.

We have many different senses in our body. In common parlance, we have five senses: taste, touch, smell, sight, and hearing. We also have an extended sensor system that plays less visible of a role in our lives: sensoriomotor/proprioception (bodily awareness), equilibrioception (balance), among others [[Sensory Trust 2003]](https://paperpile.com/c/mpEskP/6mmR). Many of these senses can alternate between an active or *background *role depending on the situation.

Among these 8+ factors, we can see how many are engaged by each of the daily tasks below:

|Daily situation|Primary task|Secondary task (usually optional)|Primary senses engaged|Secondary senses engaged|
|---|---|---|---|---|
|Brushing|Moving arm to brush teeth|N/A|Touch (active), Proprioception|N/A|
|Driving|Driving automobile|Listen to audio (music, podcast, audiobook), converse with passengers, |Sight, Touch Proprioception, Hearing (background for emergencies)|Hearing (active)|
|Cooking|Cooking food in a kitchen|Listen to audio (music, podcast, audiobook), converse with family or friends|Touch, Proprioception, Sight, Taste, Smell, Hearing (background, for alarms)|Hearing|
|Household chores|Cleaning, Laundry|Listen to audio (music, podcast, audiobook)|Touch, Proprioception, Sight, Smell|Hearing|
|Studying|Reading,Watching lectures|N/A|Sight, Hearing|N/A|
|Watching TV or YouTube|Watching a screen|Converse with friends or family, Draw|Sight, Hearing|Hearing (background)|
|Visiting an art museum|Walking around an art museum|(Usually quiet)|Sight, Proprioception (for walking)|N/A|


Opportunities for creating truly immersive and useful augmented reality systems comes at the following places:
* Look up situations in which senses are not used for a primary task and there is no secondary task (it is N/A). Explore situations where these unused senses could be used in a secondary task.
* Look up situations where a sense is not used in a primary or secondary task. Explore situations where these unused senses could be used in a different secondary task or tertiary task.

For example, when studying (and not taking notes), we do not use our sense of touch. We can create a system for augmenting our learning situation through the sense of touch using haptic interactions.

Another example, given that sight is the only major sense used during a walk in an art museum, we could provide an augmented reality experience through our auditory or touch systems. (You can imagine walking around a museum as a wearable system, like AirPods, automatically detects what you are looking at and can also use natural language queries to answer questions you have of the art work.)

We keep coming back to three main senses: touch, sight, and hearing. These form the basis for many of the interactions we have with the world around us. Integrating each of these three components into an augmented reality system has the most potential for creating an immersive and meaningful experience. By taking full advantage of the ‘sensor fusion’ in our minds that we can more effectively learn behaviors and actions, we can increase the comfort, productivity, and flow we feel in various daily tasks.


# The Design of Head-Worn Displays

Currently, HWDs form the highest-bandwidth bridge to convey information to the brain. Although implant or surface-worn BCIs could theoretically form the ideal way to convey information to and from the brain, current limitations on bandwidth make HWDs a better option.

In this section, we detail various aspects of the design of HWDs.

There are a few broad categories of use
* Consumer every-day
* Consumer gaming
* Industrial 
* Medical

Each of which requires a call upon different balances of the dimensions of design.

## Dimensions of design

### Age-related issues
### 
### Audio
#### 
#### Brain-Conducting Transmission

### Battery & Charging

### Controllers & Sensors

#### Wired vs. all on head

#### CPU

#### GPU

#### Sensors vs. not having sensors

#### Available sensors

* Acceleratormeter
* Compass
* Gyroscope

#### Sensor fusion

### Registered vs. Static AR
### 
### Human Visual Perception

#### Vergence vs. Accommodation

### Fashion: Xybernaut vs. Glass vs. North

### Human Factors

#### Sweat & Nose Pads

#### Hair

#### Don / doff: Taking it on and off

#### Fit:  “No one is average”
#### 
#### Ego motion / nausea
### 
### Optics & Display
#### 
#### Flat focus

#### Field-of-view

#### Field-of-regard

#### Monocular vs. Binocular

#### Eyebox: Binoculars, Vignetting

#### Color

#### Resolution

#### Movement while in use

#### Focal depth: static vs. fixed, multiplane (like MagicLeap)

#### Night vision

#### Positioning:
#### 
##### Consider line-of-sight and Cognitive Capture studies: Car / Plane

##### On-center vs. off-center AR
### 
#### Stereo Eyebox

#### Stray light

#### Outdoors / transparency / photochromatic
### 
### Materials

### Privacy

#### Appearance when off

#### Perception of privacy: Photochromic

### Safety

### Weight

#### Distribution along head

#### Weight on nose

### Use-cases

### Uncategorized
#### 
#### Local vs. Remote map
#### 
#### On the go: Use cases
#### 
#### Survey of concerns


## 
## Categories of use

### Consumer, every-day

Everyday consumer-wearable head-worn displays are exciting because of symbiosis between humans and machines enabled by their constant usage: Data captured and inputted into the device can build larger and larger datasets that can be analyzed and made useful to the user.

### Consumer gaming

### Professional gaming

### Industrial
### 
### Medical

In medical applications, privacy is of utmost concern requiring careful attention to the software and hardware usage of voice and camera input. Computer networking and offsite APIs will need to be carefully designed to be compliant with relevant regulations like HIPAA.
# Input mechanisms

## Standard keyboards

## Chorded keyboards

### Twiddler


# Notes

## 
|Pattie Maes TED Talk: Human-Machine SymbiosisSource: [[Maes 1997]](https://paperpile.com/c/mpEskP/se69)We become cyborgs: kids get a smartphone at age 12-14The two halves of our brains have become the biological and digitalIncreasingly, we rely on our digital brain to answer questions when we are asked something rather than using our biological brain to come up with a solution.The two halves of our brain don’t talk well together:Communication is limited: limited I/O bandwidthRequires our complete attention, disengaging us from the real world.The software hasn’t been designed with the goals of people in mind. Different apps on phone are trying to distract you as much as possible, making you as inefficient and ineffective at accomplishing goals -> multitasking, short attention spansPattie Maes: It is our destintiny to augment ourselves with whatever tools and technologies, and merge with technology itselfWe will become one with the computer, but we must redesign the experience of how someone interacts with their digital devices.Argues for a new approach:System aware of context & userAware of context and user’s internal state, what the user is paying attention to, brain activity, heart rate, breathing rate, etc.Always-on augmented interfaceSeamless, non-disruptive wayProactive, personalized interactionOffer relevant information and intervention, given what the user is currently trying to do, the user’s state, and the user’s goalPrior work: on-body camera and projectorExperience is synergistic and incorporatedExperience the physical environment and benefiting from digital informationSymbiotic relationship between users and machines will help with self-actualization, with growing and developing into the people we want to become.We all want to change and grow in different ways.We will rely on symbiotic forms of personal devices more and more to help us change with timeSymbiotic devices will change the way we make decisions, learn, remember, and regulate our moodSupporting Decision MakingUp to 90% of the decisions we make are a result of natural thinking that may not be in\line with our goalsSupport LearningUsing AR to label objects in the real world (WordSense)Can give you new words for known objects, etc.Not all of the devices need to rely on a smart AI systemGoogle Glass in a supermarket for learning a new language through a “remote assistant” systemAR for “remote assistant”Supporting MemoryShaking hand to remember someone’s name and face (TakeTwo)Uses AR with “memory palace” to help you remember/memorize a random set of facts. Only have to experience this once to remember a totally random set of facts for up to a year because it becomes associated in the brain with the physical landmarksSupporting Mood and Well-beingUses EEG to note the brain waves and a wristband to pick up heart rate/galvanic, releases a pleasant smell when it senses anxiety, sharp sense when you’re not focusing enough to wake up and pay attentionPsyhicVR: Uses EEG headband to notice brain activity in combination of VR: as long as the brain is concentrated and focused, can make things levitate or other crazy things“Let’s embrace our cyborg future but redesign our devices to a natural extension that assists and empowers”“We are cyborgs, and forever will be cyborgs”|
|---|


# Glossary of terms

|Acronym|Term|Definition|
|---|---|---|
|AI|Artificial intelligence|The field of creating computer agents comparable to humans in a variety of discrete tasks ranging from image classification to automobile driving.|
|API|Application programmers interface||
|AR|Augmented reality||
|HCD|Human-centered design||
|HCI|Human-computer interaction|A field of computer science that focuses on the medium of interaction between humans and their computers.|
|HWD|Head-worn display|Describes any display mounted on the head with information presented to the eyes and ears through a display and speakers, respectively.|
|HUD|Heads-up display|A subset of HWDs that details |
|VR|Virtual reality|A fully-immersive |


# References

[Buntz, B. Augmented Reality Technology Gaining Ground for Industrial Uses. ](http://paperpile.com/b/mpEskP/L36u)[https://www.iotworldtoday.com/2019/06/14/augmented-reality-technology-heating-up-in-industrial-space/.](https://www.iotworldtoday.com/2019/06/14/augmented-reality-technology-heating-up-in-industrial-space/.)
[Fleenor, S.E. 2019. The Seven of Nine binge guide. ](http://paperpile.com/b/mpEskP/cNpY)[SYFY WIRE](http://paperpile.com/b/mpEskP/cNpY)[. ](http://paperpile.com/b/mpEskP/cNpY)[https://www.syfy.com/syfywire/the-seven-of-nine-binge-guide.](https://www.syfy.com/syfywire/the-seven-of-nine-binge-guide.)
[Hartman, P., Bezos, J.P., Kaphan, S., and Spiegel, J. 1999. Method and system for placing a purchase order via a communications network. ](http://paperpile.com/b/mpEskP/jiKd)[US Patent](http://paperpile.com/b/mpEskP/jiKd)[. ](http://paperpile.com/b/mpEskP/jiKd)[https://patentimages.storage.googleapis.com/37/e6/81/3ebb1f33c41b4a/US5960411.pdf.](https://patentimages.storage.googleapis.com/37/e6/81/3ebb1f33c41b4a/US5960411.pdf.)
[inFORM. 2013. .](http://paperpile.com/b/mpEskP/HJKN)
[Maes, P. 1997. Pattie Maes On Sofware Agents: Humanizing The Global Computer. ](http://paperpile.com/b/mpEskP/se69)[IEEE Internet Computing 1](http://paperpile.com/b/mpEskP/se69)[, 10–19. ](http://paperpile.com/b/mpEskP/se69)[http://dx.doi.org/10.1109/mic.1997.612209.](http://dx.doi.org/10.1109/mic.1997.612209.)
[Milgram, P., Takemura, H., Utsumi, A., and Kishino, F. 1995. Augmented reality: a class of displays on the reality-virtuality continuum. ](http://paperpile.com/b/mpEskP/ZNyK)[Telemanipulator and Telepresence Technologies](http://paperpile.com/b/mpEskP/ZNyK)[, International Society for Optics and Photonics, 282–292.](http://paperpile.com/b/mpEskP/ZNyK)
[Rhodes, B.J. 1997. The wearable remembrance agent: A system for augmented memory. ](http://paperpile.com/b/mpEskP/0nl3)[Personal Technologies](http://paperpile.com/b/mpEskP/0nl3)[ ](http://paperpile.com/b/mpEskP/0nl3)[1](http://paperpile.com/b/mpEskP/0nl3)[, 4, 218–224.](http://paperpile.com/b/mpEskP/0nl3)
[Sandor, C., Fuchs, M., Cassinelli, A., et al. 2015. Breaking the barriers to true augmented reality. ](http://paperpile.com/b/mpEskP/8tj6)[arXiv preprint arXiv:1512. 05471](http://paperpile.com/b/mpEskP/8tj6)[.](http://paperpile.com/b/mpEskP/8tj6)
[Sensory Trust. 2003. Sensory Trust.5, 9, 21, 53… how many senses? ](http://paperpile.com/b/mpEskP/6mmR)[https://www.sensorytrust.org.uk/information/articles/senses.html.](https://www.sensorytrust.org.uk/information/articles/senses.html.)
[Stanford University. 2018. Heavy multitaskers have reduced memory. ](http://paperpile.com/b/mpEskP/HdB0)[Stanford News](http://paperpile.com/b/mpEskP/HdB0)[. ](http://paperpile.com/b/mpEskP/HdB0)[https://news.stanford.edu/2018/10/25/decade-data-reveals-heavy-multitaskers-reduced-memory-psychologist-says/.](https://news.stanford.edu/2018/10/25/decade-data-reveals-heavy-multitaskers-reduced-memory-psychologist-says/.)
[Virtual Room | #1 Virtual Reality Sydney | Multiplayer VR Escape Room. ](http://paperpile.com/b/mpEskP/KjLj)[Sydney](http://paperpile.com/b/mpEskP/KjLj)[. ](http://paperpile.com/b/mpEskP/KjLj)[https://sydney.virtual-room.com/.](https://sydney.virtual-room.com/.)
[Zambetta, F. 2017. Star Trek’s Holodeck: from science fiction to a new reality. ](http://paperpile.com/b/mpEskP/KEbv)[The Conversation](http://paperpile.com/b/mpEskP/KEbv)[. ](http://paperpile.com/b/mpEskP/KEbv)[http://theconversation.com/star-treks-holodeck-from-science-fiction-to-a-new-reality-74839.](http://theconversation.com/star-treks-holodeck-from-science-fiction-to-a-new-reality-74839.)


---

[^footnote-1]:  e.g. sight, vestibular, auditory, touch (with haptics), etc.
[^footnote-2]:  e.g. an ARKit iOS application for playing darts: [https://www.youtube.com/watch?v=Dg9kcm_Li08](https://www.youtube.com/watch?v=Dg9kcm_Li08)
[^footnote-3]:  information such as the location, time, people involved, retailers nearby, users nearby, etc.
[^footnote-4]:  because it was created by the Tangible Media Group :)